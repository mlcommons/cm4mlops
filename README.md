[![PyPI version](https://badge.fury.io/py/cmind.svg)](https://pepy.tech/project/cmind)
[![Python Version](https://img.shields.io/badge/python-3+-blue.svg)](https://github.com/mlcommons/ck/tree/master/cm/cmind)
[![License](https://img.shields.io/badge/License-Apache%202.0-green)](LICENSE.md)

[![CM test](https://github.com/mlcommons/ck/actions/workflows/test-cm.yml/badge.svg)](https://github.com/mlcommons/ck/actions/workflows/test-cm.yml)
[![CM script automation features test](https://github.com/mlcommons/ck/actions/workflows/test-cm-script-features.yml/badge.svg)](https://github.com/mlcommons/ck/actions/workflows/test-cm-script-features.yml)

### About

The [Collective Knowledge project (CK)](https://arxiv.org/abs/2011.01149) 
is motivated by our tedious experience reproducing experiments 
from [150 research papers](https://learning.acm.org/techtalks/reproducibility)
and validating them in the real world - we decided to collaborate with the community 
to develop a universal, human-readable and technology-agnostic interface 
to access any software project and run it on any platform with any software, hardware and data.

The [Collective Mind workflow automation framework (CM aka CK2)](https://github.com/mlcommons/ck/tree/master/cm/cmind)
is the 2nd version of the CK technology being developed by the [open MLCommons taskforce](https://github.com/mlcommons/ck/blob/master/docs/taskforce.md).
It helps users to solve the "dependency hell" and interconnect diverse and rapidly evolving software and hardware
from any company including Nvidia, Intel, Qualcomm, AMD, Microsoft, Amazon, Google, 
Neural Magic, Meta, OctoML, Krai, cKnowledge and Hugging Face in a transparent and non-intrusive way
using  [portable CM scripts  developed by the community](https://github.com/mlcommons/ck/blob/master/docs/list_of_scripts.md).

The CM framework is powering a [free and open-source automation platform](https://github.com/mlcommons/ck/tree/master/platform) 
also being developed by the [open MLCommons taskforce](https://github.com/mlcommons/ck/blob/master/docs/taskforce.md)
to help users find the most efficient and reproducible way to run their applications
with any data on any software/hardware stack from the cloud to the edge at any given time.

It automatically generates the most suitable, reproducible and deployable solution
to run AI, ML and other emerging applications based on user requirements and constraints 
including costs, throughput, latency, power consumption, accuracy, target devices (cloud/edge/mobile/tiny),
environment and data sets.

As a proof-of-concept, our technology helped the community and multiple companies 
including Qualcomm, Neural Magic, Krai, DELL, HPE and Lenovo
automate 98% of all MLPerf inference submissions, make them more reproducible and reusable,
and obtain record inference performance on the latest Qualcomm and Nvidia devices.

Our goal is to help researchers and practitioners focus on innovation by automating all their tedious and repetitive tasks
and slashing their research, development, benchmarking, optimization and deployment time and costs
by 10..100 times across continuously changing software, hardware and data.

### Discussions

Join our [Discord server](https://discord.gg/JjWNWXKxwT) 
to learn more about our technology, participate in public developments and discussions,
and request platform features and support for your technology.

### Documentation and the Getting Started Guide

* [Table of contents](https://github.com/mlcommons/ck/tree/master/docs/README.md)

### Copyright

2021-2023 [MLCommons](https://mlcommons.org)

### License

Apache 2.0

### Authors and maintainers

* [Grigori Fursin](https://cKnowledge.org/gfursin)
* [Arjun Suresh](https://www.linkedin.com/in/arjunsuresh)

### Acknowledgments

This project is supported by [MLCommons](https://mlcommons.org), [cTuning foundation](https://cTuning.org),
[cKnowledge](https://cKnowledge.org) and [individual contributors](https://github.com/mlcommons/ck/blob/master/CONTRIBUTING.md).
