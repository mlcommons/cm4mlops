name: MLPerf inference SDXL
#off now as we have SCC24 test doing the same
on:
  schedule:
    - cron: "1 2 * * *"

jobs:
  build_reference:
    if: github.repository_owner == 'gateoverflow_off'
    runs-on: [ self-hosted, linux, x64 ]
    strategy:
      fail-fast: false
      matrix:
        python-version: [ "3.12" ]
        backend: [ "pytorch" ]
        precision: [ "float16" ]
    steps:
    - name: Test MLPerf Inference SDXL Reference
      run: |
        source gh_action/bin/deactivate || python3 -m venv gh_action
        source gh_action/bin/activate
        export CM_REPOS=$HOME/GH_CM
        python3 -m pip install cm4mlops
        cm pull repo
        cm run script --tags=run-mlperf,inference,_performance-only,_short --submitter="MLCommons" --docker --model=sdxl --backend=${{ matrix.backend }} --device=cuda --scenario=Offline --test_query_count=1 --precision=${{ matrix.precision }} --target_qps=1 --quiet --docker_it=no --docker_cm_repo=gateoverflow@cm4mlops --adr.compiler.tags=gcc --hw_name=gh_action --docker_dt=yes  --results_dir=$HOME/gh_action_results --submission_dir=$HOME/gh_action_submissions --clean
        cm run script --tags=run-mlperf,inference,_short --model=sdxl --implementation=reference --backend=${{ matrix.backend }} --category=edge --scenario=Offline --execution_mode=test --device=${{ matrix.device }} --precision=${{ matrix.precision }} --docker --docker_it=no --docker_cm_repo=gateoverflow@cm4mlops --docker_dt=yes --quiet --results_dir=$HOME/gh_action_results --submission_dir=$HOME/gh_action_submissions --precision=float16 --env.CM_MLPERF_MODEL_SDXL_DOWNLOAD_TO_HOST=yes --clean
        cm run script --tags=generate,inference,submission --clean --preprocess_submission=yes --run-checker --tar=yes --env.CM_TAR_OUTFILE=submission.tar.gz --division=open --category=edge --run_style=test --adr.submission-checker.tags=_short-run --quiet --submitter=MLCommons --submission_dir=$HOME/gh_action_submissions --results_dir=$HOME/gh_action_results/test_results
        cm run script --tags=push,github,mlperf,inference,submission --repo_url=https://github.com/gateoverflow/cm4mlperf-inference --repo_branch=mlperf-inference-results-scc24 --commit_message="Results from self hosted Github actions - NVIDIARTX4090" --quiet --submission_dir=$HOME/gh_action_submissions

  build_nvidia:
      if: github.repository_owner == 'gateoverflow_off'
      runs-on: [ self-hosted, linux, x64 ]
      strategy:
        fail-fast: false
        matrix:
          python-version: [ "3.12" ]
          backend: [ "tensorrt" ]
          precision: [ "float16" ]
          implementation: [ "nvidia" ]
      steps:
      - name: Test MLPerf Inference SDXL Nvidia
        run: |
          source gh_action/bin/deactivate || python3 -m venv gh_action
          source gh_action/bin/activate
          export CM_REPOS=$HOME/GH_CM
          cm pull repo
          cm run script --tags=run-mlperf,inference,_performance-only,_short --submitter="MLCommons" --docker --model=sdxl --implementation=${{ matrix.implementation }} --backend=${{ matrix.backend }} --device=cuda --scenario=Offline --test_query_count=1 --precision=${{ matrix.precision }} --target_qps=1 --quiet --docker_it=no --docker_cm_repo=gateoverflow@cm4mlops --adr.compiler.tags=gcc --hw_name=gh_action --docker_dt=yes  --results_dir=$HOME/gh_action_results --submission_dir=$HOME/gh_action_submissions --clean
          cm run script --tags=run-mlperf,inference,_short --model=sdxl --implementation=${{ matrix.implementation }} --backend=${{ matrix.backend }} --category=edge --scenario=Offline --execution_mode=test --device=${{ matrix.device }} --precision=${{ matrix.precision }} --docker --docker_it=no --docker_cm_repo=gateoverflow@cm4mlops --docker_dt=yes --quiet --results_dir=$HOME/gh_action_results --submission_dir=$HOME/gh_action_submissions --precision=float16 --env.CM_MLPERF_MODEL_SDXL_DOWNLOAD_TO_HOST=yes --clean
          cm run script --tags=generate,inference,submission --clean --preprocess_submission=yes --run-checker --tar=yes --env.CM_TAR_OUTFILE=submission.tar.gz --division=open --category=edge --run_style=test --adr.submission-checker.tags=_short-run --quiet --submitter=MLCommons --submission_dir=$HOME/gh_action_submissions --results_dir=$HOME/gh_action_results/test_results
          cm run script --tags=push,github,mlperf,inference,submission --repo_url=https://github.com/gateoverflow/cm4mlperf-inference --repo_branch=mlperf-inference-results-scc24 --commit_message="Results from self hosted Github actions - NVIDIARTX4090" --quiet --submission_dir=$HOME/gh_action_submissions

