{
  "alias": "get-ml-model-resnet50",
  "automation_alias": "script",
  "automation_uid": "5b4e0237da074764",
  "category": "ML/AI models",
  "cache": true,
  "default_variation": "onnx",
  "env": {
    "CM_ML_MODEL": "RESNET50",
    "CM_ML_MODEL_DATASET": "imagenet2012-val",
    "CM_ML_MODEL_IMAGE_HEIGHT": "224",
    "CM_ML_MODEL_IMAGE_WIDTH": "224",
    "CM_ML_MODEL_INPUT_SHAPES": "\\\"input_tensor:0\\\": (BATCH_SIZE, 3, 224, 224)",
    "CM_ML_MODEL_NORMALIZE_DATA": "0",
    "CM_ML_MODEL_RETRAINING": "no",
    "CM_ML_MODEL_SUBTRACT_MEAN": "YES",
    "CM_ML_MODEL_WEIGHT_TRANSFORMATIONS": "no"
  },
  "new_env_keys": [
    "CM_ML_MODEL_*"
  ],
  "tags": [
    "get",
    "ml-model",
    "resnet50",
    "ml-model-resnet50",
    "image-classification"
  ],
  "uid": "56203e4e998b4bc0",
  "variations": {
    "fp32": {
      "env": {
        "CM_ML_MODEL_INPUT_DATA_TYPES": "fp32",
        "CM_ML_MODEL_PRECISION": "fp32",
        "CM_ML_MODEL_WEIGHT_DATA_TYPES": "fp32"
      }
    },
    "onnx": {
      "base": [
        "onnx-1.5-opset-11",
        "fp32"
      ]
    },
    "onnx-1.5-opset-11": {
      "base": [
        "onnx_"
      ],
      "env": {
        "CM_ML_MODEL_ONNX_OPSET": "11",
        "CM_PACKAGE_URL": "https://zenodo.org/record/4735647/files/resnet50_v1.onnx"
      }
    },
    "onnx-1.5-opset-8": {
      "env": {
        "CM_ML_MODEL_ONNX_OPSET": "8",
        "CM_PACKAGE_URL": "https://zenodo.org/record/2592612/files/resnet50_v1.onnx"
      }
    },
    "onnx_": {
      "env": {
        "CM_ML_MODEL_DATA_LAYOUT": "NCHW",
        "CM_ML_MODEL_FRAMEWORK": "onnx",
        "CM_ML_MODEL_INPUT_LAYERS": "input_tensor:0",
        "CM_ML_MODEL_INPUT_LAYER_NAME": "input_tensor:0",
        "CM_ML_MODEL_OUTPUT_LAYERS": "softmax_tensor:0",
        "CM_ML_MODEL_OUTPUT_LAYER_NAME": "softmax_tensor:0",
        "CM_ML_MODEL_VER": "1.5"
      }
    },
    "onnxruntime": {
      "base": [
        "onnx"
      ]
    },
    "pytorch": {
      "base": [
        "fp32"
      ],
      "env": {
        "CM_ML_MODEL_DATA_LAYOUT": "NCHW",
        "CM_ML_MODEL_FRAMEWORK": "pytorch",
        "CM_ML_MODEL_GIVEN_CHANNEL_MEANS": "?",
        "CM_ML_STARTING_WEIGHTS_FILENAME": "<<<CM_PACKAGE_URL>>>",
        "CM_PACKAGE_URL": "https://zenodo.org/record/4588417/files/resnet50-19c8e357.pth"
      }
    },
    "tensorflow": {
      "base": [
        "tf"
      ]
    },
    "tf": {
      "base": [
        "fp32"
      ],
      "env": {
        "CM_ML_MODEL_ACCURACY": "76.456",
        "CM_ML_MODEL_DATA_LAYOUT": "NHWC",
        "CM_ML_MODEL_FRAMEWORK": "tensorflow",
        "CM_ML_MODEL_GIVEN_CHANNEL_MEANS": "123.68 116.78 103.94",
        "CM_ML_MODEL_INPUT_LAYERS": "input_tensor",
        "CM_ML_MODEL_INPUT_LAYER_NAME": "input_tensor",
        "CM_ML_MODEL_NORMALIZE_DATA": "0",
        "CM_ML_MODEL_OUTPUT_LAYERS": "softmax_tensor",
        "CM_ML_MODEL_OUTPUT_LAYER_NAME": "softmax_tensor",
        "CM_ML_MODEL_STARTING_WEIGHTS_FILENAME": "<<<CM_PACKAGE_URL>>>",
        "CM_ML_MODEL_SUBTRACT_MEAN": "YES",
        "CM_PACKAGE_URL": "https://zenodo.org/record/2535873/files/resnet50_v1.pb"
      }
    },
    "uint8": {
      "env": {
        "CM_ML_MODEL_INPUT_DATA_TYPES": "uint8",
        "CM_ML_MODEL_PRECISION": "uint8",
        "CM_ML_MODEL_WEIGHT_DATA_TYPES": "uint8"
      }
    }
  }
}
