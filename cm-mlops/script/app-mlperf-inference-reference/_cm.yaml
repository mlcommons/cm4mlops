# Identification of this CM script
alias: app-mlperf-inference-reference
uid: d775cac873ee4231

automation_alias: script
automation_uid: 5b4e0237da074764

# User-friendly tags to find this CM script
tags:
  - app
  - vision
  - language
  - mlcommons
  - mlperf
  - inference
  - reference
  - generic
  - ref

# Default environment
default_env:
  CM_BATCH_COUNT: '1'
  CM_BATCH_SIZE: '1'
  CM_LOADGEN_MODE: accuracy
  CM_LOADGEN_SCENARIO: Offline
  CM_OUTPUT_FOLDER_NAME: test_results
  CM_MLPERF_RUN_STYLE: test
  CM_TEST_QUERY_COUNT: '10'

# Map script inputs to environment variables
input_mapping:
  count: CM_LOADGEN_QUERY_COUNT
  docker: CM_RUN_DOCKER_CONTAINER
  hw_name: CM_HW_NAME
  imagenet_path: IMAGENET_PATH
  max_batchsize: CM_LOADGEN_MAX_BATCHSIZE
  mode: CM_LOADGEN_MODE
  num_threads: CM_NUM_THREADS
  output_dir: OUTPUT_BASE_DIR
  power: CM_SYSTEM_POWER
  regenerate_files: CM_REGENERATE_MEASURE_FILES
  rerun: CM_RERUN
  scenario: CM_LOADGEN_SCENARIO
  test_query_count: CM_TEST_QUERY_COUNT

# Duplicate CM environment variables to the ones used in native apps
env_key_mappings:
  CM_HOST_: HOST_
  CM_ML_: ML_

# Env keys which are exposed to higher level scripts
new_env_keys:
  - CM_MLPERF_*


# Dependencies on other CM scripts
deps:

  # Detect host OS features
  - tags: detect,os
  
  # Detect host CPU features
  - tags: detect,cpu

  # Install system dependencies on a given host
  - tags: get,sys-utils-cm

  # Detect/install python
  - tags: get,python
    names:
    - python3
    
  # Detect CUDA if required
  - tags: get,cuda
    enable_if_env:
      CM_DEVICE:
      - gpu


  ########################################################################
  # Install MLPerf inference dependencies
  
  # Install MLPerf loadgen
  - tags: get,loadgen
    names:
    - loadgen
    
  # Download MLPerf inference source
  - tags: get,mlcommons,inference,src
    names:
    - inference-src
    
  # Get SUT configs (System Under Test)
  - tags: get,sut,configs



  ########################################################################
  # Install ML engines via CM

  ## Onnx Runtime
  - tags: get,generic-python-lib,_onnxruntime
    names:
    - ml-engine-onnxruntime
    enable_if_env:
      CM_BACKEND:
      - onnxruntime
      - tvm-onnx
      - tvm-pip-install-onnx
    
  ## Pytorch
  - tags: get,generic-python-lib,_torch
    names:
    - ml-engine-pytorch
    enable_if_env:
      CM_BACKEND:
      - pytorch

  ## Transformers
  - tags: get,generic-python-lib,_transformers
    names:
    - ml-engine-transformers
    enable_if_env:
      CM_MODEL:
      - bert-99.9

  ## Tensorflow
  - tags: get,generic-python-lib,_tensorflow
    names:
    - ml-engine-tensorflow
    enable_if_env:
      CM_BACKEND:
      - tf
      - tflite

  ## TVM with LLVM and ONNX models
  - tags: get,tvm,_llvm
    names:
    - ml-engine-tvm
    enable_if_env:
      CM_BACKEND:
      - tvm-onnx
    skip_if_env:
      CM_TVM_PIP_INSTALL: []
    
    
      


  ########################################################################
  # Install datasets

  ## ImageNet (small for tests)
  - tags: get,dataset,image-classification,imagenet,preprocessed
    names: 
    - imagenet-preprocessed
    enable_if_env:
      CM_MODEL:
      - resnet50

  - tags: get,dataset-aux,image-classification,imagenet-aux
    enable_if_env:
      CM_MODEL:
      - resnet50

  ## Open Images (full) for RetinaNet
  - tags: get,dataset,object-detection,open-images,preprocessed
    enable_if_env:
      CM_MODEL:
      - retinanet
    
  - tags: get,generic-python-lib,_pycocotools
    enable_if_env:
      CM_MODEL:
      - retinanet
    
  ## Squad for BERT
  - tags: get,dataset,squad,original
    enable_if_env:
      CM_MODEL:
      - bert-99.9
    


  ########################################################################
  # Install ML models    

  ## ResNet50 (ONNX format, FP32)
  - tags: get,ml-model,image-classification,resnet50,_onnx
    enable_if_env:
      CM_BACKEND:
      - onnxruntime
      - tvm-onnx
      CM_MODEL:
      - resnet50

  ## ResNet50 (Tensorflow format, FP32)
  - tags: get,ml-model,image-classification,resnet50,_tensorflow
    enable_if_env:
      CM_BACKEND:
      - tf
      - tflite
      CM_MODEL:
      - resnet50

  ## ResNet50 (PyTorch format, FP32)
  - tags: get,ml-model,image-classification,resnet50,_pytorch
    enable_if_env:
      CM_BACKEND:
      - pytorch
      CM_MODEL:
      - resnet50
    
  ## RetinaNet (ONNX format, FP32)
  - tags: get,ml-model,object-detection,resnext50,fp32,_onnx
    enable_if_env:
      CM_BACKEND:
      - onnxruntime
      CM_MODEL:
      - retinanet
    
  ## RetinaNet (PyTorch format, FP32)
  - tags: get,ml-model,object-detection,resnext50,fp32,_pytorch
    enable_if_env:
      CM_BACKEND:
      - pytorch
      CM_MODEL:
      - retinanet
  
  ## BERT (ONNX format)
  - tags: get,ml-model,language-processing,bert,_onnx-fp32
    enable_if_env:
      CM_BACKEND:
      - onnxruntime
      CM_MODEL:
      - bert-99.9

  ## BERT (TF format)
  - tags: get,ml-model,language-processing,bert,_tf
    enable_if_env:
      CM_BACKEND:
      - tf
      CM_MODEL:
      - bert-99.9
 
  ## BERT (Pytorch format)
  - tags: get,ml-model,language-processing,bert,_pytorch-fp32
    enable_if_env:
      CM_BACKEND:
      - pytorch
      CM_MODEL:
      - bert-99.9

  - tags: get,generic-python-lib,_tokenization
    enable_if_env:
      CM_MODEL:
      - bert-99.9
    








# Variations to customize dependencies
variations:
  # Implementation (CPP or Python)
  cpp:
    add_deps_recursive:
      imagenet-accuracy-script:
        tags: _int64
    env:
      CM_MLPERF_CPP: 'yes'
    posthook_deps:
      - names:
         - cpp-mlperf-inference
        tags: app,mlperf,cpp,inference

  python:
    add_deps_recursive:
      imagenet-accuracy-script:
        tags: _float32
    env:
      CM_MLPERF_PYTHON: 'yes'
  
  # ML engine
  onnxruntime:
    add_deps_recursive:
      imagenet-preprocessed:
        tags: _NCHW
      cpp-mlperf-inference:
        tags: _onnxruntime
    env:
      CM_BACKEND: onnxruntime
      CM_BACKEND_VERSION: <<<CM_ONNXRUNTIME_VERSION>>>

  pytorch:
    env:
      CM_BACKEND: pytorch
      CM_BACKEND_VERSION: <<<CM_PYTORCH_VERSION>>>

  tf:
    add_deps_recursive:
      imagenet-preprocessed:
        tags: _NHWC
    env:
      CM_BACKEND: tf
      CM_BACKEND_VERSION: <<<CM_TENSORFLOW_VERSION>>>

  tflite:
    env:
      CM_BACKEND: tflite

  tvm-onnx:
    env:
      CM_BACKEND: tvm-onnx
      CM_BACKEND_VERSION: <<<CM_ONNXRUNTIME_VERSION>>>

  tvm-pip-install-onnx:
    deps:
    - names:
      - tvm
      - ml-engine-tvm
      tags: get,generic-python-lib,_apache-tvm
    env:
      CM_BACKEND: tvm
      CM_TVM_PIP_INSTALL: true

 
  # Reference MLPerf models
  bert-99.9:
    env:
      CM_MODEL: bert-99.9
    post_deps:
    - enable_if_env:
        CM_LOADGEN_MODE:
        - accuracy
        - all
        CM_MLPERF_ACCURACY_RESULTS_DIR:
        - 'on'
      names:
      - squad-accuracy-script
      - mlperf-accuracy-script
      tags: run,accuracy,mlperf,_squad,_float32

  retinanet:
    env:
      CM_MODEL: retinanet
    post_deps:
    - enable_if_env:
        CM_LOADGEN_MODE:
        - accuracy
        - all
        CM_MLPERF_ACCURACY_RESULTS_DIR:
        - 'on'
      names:
      - mlperf-accuracy-script
      - openimages-accuracy-script
      tags: run,accuracy,mlperf,_openimages

  resnet50:
    env:
      CM_MODEL: resnet50
    post_deps:
    - enable_if_env:
        CM_LOADGEN_MODE:
        - accuracy
        - all
        CM_MLPERF_ACCURACY_RESULTS_DIR:
        - 'on'
      names:
      - mlperf-accuracy-script
      - imagenet-accuracy-script
      tags: run,accuracy,mlperf,_imagenet

  # Target devices
  cpu:
    env:
      CM_DEVICE: cpu
      USE_GPU: no

  gpu:
    env:
      CM_DEVICE: gpu
      USE_GPU: yes
    add_deps_recursive:
      cpp-mlperf-inference:
        tags: _gpu

  # Execution modes
  fast:
    env:
      CM_FAST_FACTOR: '5'
      CM_OUTPUT_FOLDER_NAME: fast_results
      CM_MLPERF_RUN_STYLE: fast

  test:
    env:
      CM_OUTPUT_FOLDER_NAME: test_results
      CM_MLPERF_RUN_STYLE: test

  valid:
    env:
      CM_OUTPUT_FOLDER_NAME: valid_results
      CM_MLPERF_RUN_STYLE: valid


  # Reproducibility (past submissions)
  r2.1_default:
    add_deps_recursive:
      compiler:
        tags: llvm
      inference-src:
        tags: _octoml
      loadgen:
        version: r2.1
    env:
      CM_RERUN: 'yes'
      CM_SKIP_SYS_UTILS: 'yes'
      CM_TEST_QUERY_COUNT: '100'
