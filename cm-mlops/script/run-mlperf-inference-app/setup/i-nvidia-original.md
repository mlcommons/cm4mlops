Note: Nvidia implementation require extra CM command to build and run Docker container

```bash
cm docker script --tags=build,nvidia,inference,server
```
You can then copy/paste CM commands generated by this GUI to run MLPerf benchmarks.

You can also benchmark all models in one go using this command:
```bash
cmr "benchmark any _phoenix"
```

Container will require around 60GB of free disk space.
Docker cache and running all models (without DLRM) will require ~600 GB free disk space.
