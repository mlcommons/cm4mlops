{
  "alias": "run-mlperf-inference-app",
  "automation_alias": "script",
  "automation_uid": "5b4e0237da074764",
  "category": "Modular MLPerf inference benchmark pipeline",
  "clean_output_files": [
    "open.tar.gz",
    "summary.csv",
    "summary.json"
  ],
  "default_env": {
    "CM_MLPERF_IMPLEMENTATION": "reference",
    "CM_MLPERF_MODEL": "resnet50",
    "CM_MLPERF_RUN_STYLE": "test",
    "CM_OUTPUT_FOLDER_NAME": "test_results"
  },
  "deps": [
    {
      "tags": "detect,os"
    },
    {
      "tags": "detect,cpu"
    },
    {
      "names": [
        "python",
        "python3"
      ],
      "tags": "get,python3"
    },
    {
      "names": [
        "inference-src"
      ],
      "tags": "get,mlcommons,inference,src"
    },
    {
      "tags": "get,sut,description"
    }
  ],
  "docker": {
    "fake_run_deps": true,
    "mounts": [
      "${{ GPTJ_CHECKPOINT_PATH }}:${{ GPTJ_CHECKPOINT_PATH }}",
      "${{ INSTALL_DATA_PATH }}:/install_data",
      "${{ DATA_PATH }}:/data"
    ],
    "run": true
  },
  "gui_title": "CM GUI to run the MLPerf inference benchmark and prepare submissions",
  "input_description": {
    "adr.compiler.tags": {
      "default": "gcc",
      "desc": "Compiler for loadgen and any C/C++ part of implementation"
    },
    "adr.inference-src-loadgen.env.CM_GIT_URL": {
      "default": "",
      "desc": "Git URL for MLPerf inference sources to build LoadGen (to enable non-reference implementations)"
    },
    "adr.inference-src.env.CM_GIT_URL": {
      "default": "",
      "desc": "Git URL for MLPerf inference sources to run benchmarks (to enable non-reference implementations)"
    },
    "adr.mlperf-inference-implementation.max_batchsize": {
      "desc": "Maximum batchsize to be used"
    },
    "adr.mlperf-inference-implementation.num_threads": {
      "desc": "Number of threads (reference&C++ implementation only)"
    },
    "adr.python.name": {
      "default": "mlperf",
      "desc": "Python virtual environment name (optional)"
    },
    "adr.python.version": {
      "desc": "Force Python version (must have all system deps)"
    },
    "adr.python.version_min": {
      "default": "3.8",
      "desc": "Minimal Python version"
    },
    "backend": {
      "choices": [
        "onnxruntime",
        "tf",
        "pytorch",
        "deepsparse",
        "tensorrt",
        "tvm-onnx"
      ],
      "default": "onnxruntime",
      "desc": "MLPerf backend"
    },
    "clean": {
      "boolean": true,
      "default": true,
      "desc": "Clean run"
    },
    "compliance": {
      "choices": [
        "yes",
        "no"
      ],
      "default": "yes",
      "desc": "Whether to run compliance tests (applicable only for closed division)"
    },
    "dashboard_wb_project": {
      "default": "cm-mlperf-dse-testing",
      "desc": "W&B dashboard project"
    },
    "dashboard_wb_user": {
      "default": "cmind",
      "desc": "W&B dashboard user"
    },
    "device": {
      "choices": [
        "cpu",
        "cuda"
      ],
      "default": "cpu",
      "desc": "MLPerf device"
    },
    "execution_mode": {
      "choices": [
        "test",
        "fast",
        "valid"
      ],
      "default": "test",
      "desc": "Execution mode"
    },
    "hw_name": {
      "default": "default",
      "desc": "MLPerf hardware name (from [here](https://github.com/mlcommons/ck/tree/master/cm-mlops/script/get-mlperf-inference-sut-description/hardware))"
    },
    "implementation": {
      "choices": [
        "reference",
        "cpp",
        "nvidia-original",
        "tflite-cpp"
      ],
      "default": "reference",
      "desc": "MLPerf implementation"
    },
    "mode": {
      "choices": [
        "",
        "accuracy",
        "performance"
      ],
      "default": "",
      "desc": "MLPerf mode"
    },
    "model": {
      "choices": [
        "resnet50",
        "retinanet",
        "bert-99",
        "bert-99.9",
        "3d-unet",
        "rnnt"
      ],
      "default": "resnet50",
      "desc": "MLPerf model"
    },
    "multistream_target_latency": {
      "desc": "Set MultiStream target latency"
    },
    "offline_target_qps": {
      "desc": "Set LoadGen Offline target QPS"
    },
    "precision": {
      "choices": [
        "fp32",
        "int8"
      ],
      "default": "",
      "desc": "MLPerf model precision"
    },
    "quiet": {
      "boolean": true,
      "default": false,
      "desc": "Quiet run (select default values for all questions)"
    },
    "results_dir": {
      "desc": "Folder path where run results should be stored (defaults to the current working directory)"
    },
    "scenario": {
      "choices": [
        "Offline",
        "Server",
        "SingleStream",
        "MultiStream"
      ],
      "default": "Offline",
      "desc": "MLPerf scenario"
    },
    "server_target_qps": {
      "desc": "Set Server target QPS"
    },
    "singlestream_target_latency": {
      "desc": "Set SingleStream target latency"
    },
    "submission_dir": {
      "desc": "Folder path where submission tree (to be submitted) must be stored"
    },
    "submitter": {
      "default": "TheCommunity",
      "desc": "Submitter name (without space)"
    },
    "target_latency": {
      "desc": "Set Target latency"
    },
    "target_qps": {
      "desc": "Set LoadGen target QPS"
    }
  },
  "input_mapping": {
    "backend": "CM_MLPERF_BACKEND",
    "category": "CM_MLPERF_SUBMISSION_SYSTEM_TYPE",
    "clean": "CM_MLPERF_CLEAN_ALL",
    "compliance": "CM_MLPERF_LOADGEN_COMPLIANCE",
    "dashboard_wb_project": "CM_MLPERF_DASHBOARD_WANDB_PROJECT",
    "dashboard_wb_user": "CM_MLPERF_DASHBOARD_WANDB_USER",
    "debug": "CM_DEBUG_SCRIPT_BENCHMARK_PROGRAM",
    "device": "CM_MLPERF_DEVICE",
    "division": "CM_MLPERF_SUBMISSION_DIVISION",
    "execution_mode": "CM_MLPERF_EXECUTION_MODE",
    "find_performance": "CM_MLPERF_FIND_PERFORMANCE_MODE",
    "gpu_name": "CM_NVIDIA_GPU_NAME",
    "hw_name": "CM_HW_NAME",
    "hw_notes_extra": "CM_MLPERF_SUT_SW_NOTES_EXTRA",
    "implementation": "CM_MLPERF_IMPLEMENTATION",
    "lang": "CM_MLPERF_IMPLEMENTATION",
    "mode": "CM_MLPERF_LOADGEN_MODE",
    "model": "CM_MLPERF_MODEL",
    "multistream_target_latency": "CM_MLPERF_LOADGEN_MULTISTREAM_TARGET_LATENCY",
    "offline_target_qps": "CM_MLPERF_LOADGEN_OFFLINE_TARGET_QPS",
    "output_dir": "OUTPUT_BASE_DIR",
    "output_summary": "MLPERF_INFERENCE_SUBMISSION_SUMMARY",
    "output_tar": "MLPERF_INFERENCE_SUBMISSION_TAR_FILE",
    "power": "CM_SYSTEM_POWER",
    "precision": "CM_MLPERF_MODEL_PRECISION",
    "preprocess_submission": "CM_RUN_MLPERF_SUBMISSION_PREPROCESSOR",
    "push_to_github": "CM_MLPERF_RESULT_PUSH_TO_GITHUB",
    "readme": "CM_MLPERF_README",
    "regenerate_files": "CM_REGENERATE_MEASURE_FILES",
    "regenerate_accuracy_file": "CM_MLPERF_REGENERATE_ACCURACY_FILE",
    "rerun": "CM_RERUN",
    "results_dir": "OUTPUT_BASE_DIR",
    "results_git_url": "CM_MLPERF_RESULTS_GIT_REPO_URL",
    "run_checker": "CM_RUN_SUBMISSION_CHECKER",
    "run_style": "CM_MLPERF_EXECUTION_MODE",
    "scenario": "CM_MLPERF_LOADGEN_SCENARIO",
    "server_target_qps": "CM_MLPERF_LOADGEN_SERVER_TARGET_QPS",
    "singlestream_target_latency": "CM_MLPERF_LOADGEN_SINGLESTREAM_TARGET_LATENCY",
    "skip_submission_generation": "CM_MLPERF_SKIP_SUBMISSION_GENERATION",
    "skip_truncation": "CM_SKIP_TRUNCATE_ACCURACY",
    "submission_dir": "CM_MLPERF_SUBMISSION_DIR",
    "submitter": "CM_MLPERF_SUBMITTER",
    "sw_notes_extra": "CM_MLPERF_SUT_SW_NOTES_EXTRA",
    "system_type": "CM_MLPERF_SUBMISSION_SYSTEM_TYPE",
    "target_latency": "CM_MLPERF_LOADGEN_TARGET_LATENCY",
    "target_qps": "CM_MLPERF_LOADGEN_TARGET_QPS",
    "test_query_count": "CM_TEST_QUERY_COUNT",
    "network": "CM_NETWORK_LOADGEN",
    "imagenet_path": "IMAGENET_PATH",
    "sut_servers": "CM_NETWORK_LOADGEN_SUT_SERVERS"
  },
  "new_state_keys": [
    "app_mlperf_inference_*"
  ],
  "tags": [
    "run",
    "generate-run-cmds",
    "run-mlperf",
    "vision",
    "mlcommons",
    "mlperf",
    "inference",
    "reference"
  ],
  "uid": "4a5d5b13fd7e4ac8",
  "variations": {
    "accuracy-only": {
      "default_variations": {
        "submission-generation-style": "full"
      },
      "env": {
        "CM_MLPERF_LOADGEN_MODE": "accuracy",
        "CM_MLPERF_SUBMISSION_RUN": "yes",
        "CM_RUN_MLPERF_ACCURACY": "on",
        "CM_RUN_SUBMISSION_CHECKER": "no"
      },
      "group": "submission-generation"
    },
    "all-modes": {
      "env": {
        "CM_MLPERF_LOADGEN_ALL_MODES": "yes"
      },
      "group": "mode"
    },
    "all-scenarios": {
      "env": {
        "CM_MLPERF_LOADGEN_ALL_SCENARIOS": "yes"
      }
    },
    "compliance": {
      "env": {
        "CM_MLPERF_LOADGEN_COMPLIANCE": "yes"
      }
    },
    "dashboard": {
      "default_gui": true,
      "env": {
        "CM_MLPERF_DASHBOARD": "on"
      }
    },
    "find-performance": {
      "default": true,
      "env": {
        "CM_MLPERF_FIND_PERFORMANCE_MODE": "yes",
        "CM_MLPERF_LOADGEN_ALL_MODES": "no",
        "CM_MLPERF_LOADGEN_MODE": "performance",
        "CM_MLPERF_RESULT_PUSH_TO_GITHUB": false
      },
      "group": "submission-generation"
    },
    "full": {
      "add_deps_recursive": {
        "imagenet-original": {
          "tags": "_full"
        },
        "imagenet-preprocessed": {
          "tags": "_full"
        },
        "openimages-original": {
          "tags": "_full"
        },
        "openimages-preprocessed": {
          "tags": "_full"
        },
        "openorca-original": {
          "tags": "_full"
        },
        "openorca-preprocessed": {
          "tags": "_full"
        },
        "coco2014-original": {
          "tags": "_full"
        },
        "coco2014-preprocessed": {
          "tags": "_full"
        }
      },
      "env": {
        "CM_MLPERF_SUBMISSION_GENERATION_STYLE": "full"
      },
      "group": "submission-generation-style"
    },
    "performance-only": {
      "default_variations": {
        "submission-generation-style": "full"
      },
      "env": {
        "CM_MLPERF_LOADGEN_MODE": "performance",
        "CM_MLPERF_SUBMISSION_RUN": "yes",
        "CM_RUN_SUBMISSION_CHECKER": "no"
      },
      "group": "submission-generation"
    },
    "populate-readme": {
      "base": [
        "all-modes"
      ],
      "default_variations": {
        "submission-generation-style": "full"
      },
      "env": {
        "CM_MLPERF_README": "yes",
        "CM_MLPERF_SUBMISSION_RUN": "yes",
        "CM_RUN_SUBMISSION_CHECKER": "no"
      },
      "group": "submission-generation"
    },
    "r2.1": {
      "env": {
        "CM_RUN_MLPERF_INFERENCE_APP_DEFAULTS": "r2.1_default"
      },
      "group": "reproducibility"
    },
    "r3.0": {
      "env": {
        "CM_RUN_MLPERF_INFERENCE_APP_DEFAULTS": "r3.0_default"
      },
      "group": "reproducibility"
    },
    "r3.1": {
      "env": {
        "CM_RUN_MLPERF_INFERENCE_APP_DEFAULTS": "r3.1_default"
      },
      "group": "reproducibility"
    },
    "r4.0": {
      "env": {
        "CM_RUN_MLPERF_INFERENCE_APP_DEFAULTS": "r4.0_default"
      },
      "default": true,
      "group": "reproducibility"
    },
    "short": {
      "add_deps_recursive": {
        "submission-checker": {
          "tags": "_short-run"
        }
      },
      "default": "true",
      "env": {
        "CM_MLPERF_SUBMISSION_GENERATION_STYLE": "short"
      },
      "group": "submission-generation-style"
    },
    "submission": {
      "base": [
        "all-modes"
      ],
      "default_gui": true,
      "default_variations": {
        "submission-generation-style": "full"
      },
      "env": {
        "CM_MLPERF_LOADGEN_COMPLIANCE": "yes",
        "CM_MLPERF_SUBMISSION_RUN": "yes",
        "CM_RUN_MLPERF_ACCURACY": "on",
        "CM_RUN_SUBMISSION_CHECKER": "yes",
        "CM_TAR_SUBMISSION_DIR": "yes"
      },
      "group": "submission-generation",
      "post_deps": [
        {
          "names": [
            "submission-generator"
          ],
          "skip_if_env": {
            "CM_MLPERF_SKIP_SUBMISSION_GENERATION": [
              "yes",
              "True"
            ]
          },
          "tags": "generate,mlperf,inference,submission"
        }
      ]
    }
  },
  "versions": {
    "master": {},
    "r2.1": {}
  }
}
