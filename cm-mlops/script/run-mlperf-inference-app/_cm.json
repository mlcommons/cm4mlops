{
  "alias": "run-mlperf-inference-app",
  "automation_alias": "script",
  "automation_uid": "5b4e0237da074764",
  "category": "Modular MLPerf benchmarks",
  "clean_output_files": [
    "open.tar.gz",
    "summary.csv",
    "summary.json"
  ],
  "deps": [
    {
      "tags": "detect,os"
    },
    {
      "tags": "detect,cpu"
    },
    {
      "names": [
        "python",
        "python3"
      ],
      "tags": "get,python3"
    },
    {
      "names": [
        "inference-src"
      ],
      "tags": "get,mlcommons,inference,src"
    }
  ],
  "default_env": {
    "CM_OUTPUT_FOLDER_NAME": "test_results",
    "CM_MLPERF_RUN_STYLE": "test",
    "CM_MLPERF_MODEL": "resnet50",
    "CM_MLPERF_IMPLEMENTATION": "reference",
    "CM_MLPERF_BACKEND": "onnxruntime",
    "CM_MLPERF_DEVICE": "cpu"
  },
  "input_mapping": {
    "lang": "CM_MLPERF_IMPLEMENTATION",
    "implementation": "CM_MLPERF_IMPLEMENTATION",
    "device": "CM_MLPERF_DEVICE",
    "submitter": "CM_MLPERF_SUBMITTER",
    "backend": "CM_MLPERF_BACKEND",
    "model": "CM_MLPERF_MODEL",
    "run_style": "CM_MLPERF_EXECUTION_MODE",
    "execution_mode": "CM_MLPERF_EXECUTION_MODE",
    "rerun": "CM_RERUN",
    "hw_name": "CM_HW_NAME",
    "imagenet_path": "IMAGENET_PATH",
    "max_batchsize": "CM_MLPERF_LOADGEN_MAX_BATCHSIZE",
    "mode": "CM_MLPERF_LOADGEN_MODE",
    "num_threads": "CM_NUM_THREADS",
    "output_dir": "OUTPUT_BASE_DIR",
    "results_dir": "OUTPUT_BASE_DIR",
    "submission_dir": "CM_MLPERF_SUBMISSION_DIR",
    "power": "CM_SYSTEM_POWER",
    "regenerate_files": "CM_REGENERATE_MEASURE_FILES",
    "scenario": "CM_MLPERF_LOADGEN_SCENARIO",
    "precision": "CM_MLPERF_MODEL_PRECISION",
    "test_query_count": "CM_TEST_QUERY_COUNT",
    "run_checker": "CM_RUN_SUBMISSION_CHECKER",
    "skip_truncation": "CM_SKIP_TRUNCATE_ACCURACY",
    "clean": "CM_MLPERF_CLEAN_ALL",
    "new_tvm_model": "CM_MLPERF_DELETE_COMPILED_MODEL",
    "target_qps": "CM_MLPERF_LOADGEN_TARGET_QPS",
    "offline_target_qps": "CM_MLPERF_LOADGEN_OFFLINE_TARGET_QPS",
    "server_target_qps": "CM_MLPERF_LOADGEN_SERVER_TARGET_QPS",
    "target_latency": "CM_MLPERF_LOADGEN_TARGET_LATENCY",
    "singlestream_target_latency": "CM_MLPERF_LOADGEN_SINGLESTREAM_TARGET_LATENCY",
    "multistream_target_latency": "CM_MLPERF_LOADGEN_MULTISTREAM_TARGET_LATENCY"
  },
  "tags": [
    "run",
    "generate-run-cmds",
    "run-mlperf",
    "vision",
    "mlcommons",
    "mlperf",
    "inference",
    "reference"
  ],
  "uid": "4a5d5b13fd7e4ac8",
  "variations": {
    "all-modes": {
      "env": {
        "CM_MLPERF_LOADGEN_ALL_MODES": "yes"
      }
    },
    "all-scenarios": {
      "deps": [
        {
          "tags": "get,sut,description"
        }
      ],
      "env": {
        "CM_MLPERF_LOADGEN_ALL_SCENARIOS": "yes"
      }
    },
    "compliance": {
      "env": {
        "CM_MLPERF_LOADGEN_COMPLIANCE": "yes"
      }
    },
    "submission": {
      "default_gui": true,
      "base": [
        "all-modes"
      ],
      "env": {
        "CM_MLPERF_SUBMISSION_RUN": "yes",
        "CM_RUN_SUBMISSION_CHECKER": "yes",
        "CM_TAR_SUBMISSION_DIR": "yes",
        "CM_RUN_MLPERF_ACCURACY": "on"
      },
      "post_deps": [
        {
          "tags": "get,sut,description"
        },
        {
          "tags": "generate,mlperf,inference,submission",
          "names": [
             "submission-generator"
          ]
        }
      ]
    },
    "short": {
      "group": "submission-generation-style",
      "default": "true",
      "env": {
        "CM_MLPERF_SUBMISSION_GENERATION_STYLE": "short"
      },
      "add_deps_recursive": {
        "submission-checker": {
          "tags": "_short-run"
        }
      }
    },
    "full": {
      "group": "submission-generation-style",
      "env": {
        "CM_MLPERF_SUBMISSION_GENERATION_STYLE": "full"
      }
    },
    "dashboard": {
      "default_gui": true,
      "env": {
        "CM_MLPERF_DASHBOARD": "on"
      }
    }
  },
  "versions": {
    "master": {},
    "r2.1": {}
  },
  "input_description": {
    "adr.python.name" : {
      "desc": "Python virtual environment name (optional)",
      "default": "mlperf"
    },
    "adr.python.version_min": {
      "desc": "Minimal Python version",
      "default": "3.8"
    },
    "adr.python.version": {
      "desc": "Force Python version (must have all system deps)"
    },
    "adr.compiler.tags": {
      "desc": "Compiler for loadgen",
      "default": "gcc"
    },
    "submitter": {
      "desc":"Submitter name (without space)",
      "default": "TheCommunity"
    },
    "hw_name": {
      "desc": "MLPerf hardware name (from [here](https://github.com/mlcommons/ck/tree/master/cm-mlops/script/get-mlperf-inference-sut-description/hardware))",
      "default":"default"
    },
    "implementation": {
      "desc":"MLPerf implementation",
      "default":"reference",
      "choices": ["reference"]
    },
    "model": {
      "desc":"MLPerf model",
      "default":"resnet50",
      "choices": ["resnet50"]
    },
    "backend": {
      "desc": "MLPerf backend",
      "default": "onnxruntime",
      "choices": ["onnxruntime"]
    },
    "device": {
      "desc":"MLPerf device",
      "default": "cpu",
      "choices": ["cpu", "cuda"]
    },
    "scenario": {
      "desc": "MLPerf scenario",
      "default": "Offline",
      "choices": ["Offline", "Server", "SingleStream", "MultiStream"]
    },
    "mode": {
      "desc": "MLPerf mode",
      "default": "",
      "choices": ["", "accuracy", "performance"]
    },
    "run_style": {
       "desc": "Run style",
       "default": ""
    },
    "test_query_count": {
      "desc": "Query count",
      "default": ""
    },
    "max_batchsize": {
      "desc": "Maximum batchsize to be used",
      "default": "1"
    },
    "num_threads": { 
      "desc": "Number of CPU threads to launch the application with",
      "default": ""
    },
    "clean": {
      "desc": "Clean run",
      "boolean": true,
      "default": true
    },
    "quiet": {
      "desc": "Quiet run (select default values for all questions)",
      "boolean": true,
      "default": false
    }
  }
}
