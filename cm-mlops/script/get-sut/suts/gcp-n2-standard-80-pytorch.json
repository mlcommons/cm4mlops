{
  "accelerator_frequency": "",
  "accelerator_host_interconnect": "",
  "accelerator_interconnect": "",
  "accelerator_interconnect_topology": "",
  "accelerator_memory_capacity": "N/A",
  "accelerator_memory_configuration": "",
  "accelerator_model_name": "N/A",
  "accelerator_on-chip_memories": "",
  "accelerators_per_node": "0",
  "cooling": "",
  "division": "open",
  "framework": "Pytorch 1.8.0 (out of the box MLPerf)",
  "host_memory_capacity": "320GB",
  "host_memory_configuration": "",
  "host_networking": "",
  "host_networking_topology": "",
  "host_processor_caches": "L1d cache: 1.3 MiB; L1i cache: 1.3 MiB; L2 cache: 40 MiB; L3 cache: 66 MiB",
  "host_processor_core_count": "20",
  "host_processor_frequency": "2.80GHz",
  "host_processor_interconnect": "",
  "host_processor_model_name": "Intel(R) Xeon(R) CPU (Intel Cascade Lake CPU platform)",
  "host_processors_per_node": "2",
  "host_storage_capacity": "500 GiB",
  "host_storage_type": "",
  "hw_notes": "vCPU: 80",
  "number_of_nodes": "1",
  "operating_system": "Ubuntu 20.04.1 LTS (Linux-5.8.0-1038-gcp-x86_64-with-glibc2.31)",
  "other_software_stack": "5.8.0-1038-gcp; Python 3.8.10; GCC 9.4.0",
  "status": "available",
  "submitter": "OctoML",
  "sw_notes": "Powered by Collective Mind (CK2)",
  "system_name": "Google (Google Compute Engine) n2-standard-80",
  "system_type": "edge"
}
