diff -Naur repo-orig/src/model.py repo/src/model.py
--- repo-orig/src/model.py	Fri Mar 08 20:37:32 2024
+++ repo/src/model.py	Fri Mar 08 20:53:03 2024
@@ -4,7 +4,9 @@
 import torch
 import torch.nn as nn
 from torchvision.models.resnet import resnet50
-from torchvision.models.mobilenet import mobilenet_v2, InvertedResidual
+#from torchvision.models.mobilenet import mobilenet_v2, InvertedResidual
+from torchvision.models.mobilenet import mobilenet_v2
+from torchvision.models.mobilenetv2 import InvertedResidual
 
 class Base(nn.Module):
     def __init__(self):
diff -Naur repo-orig/test_image.py repo/test_image.py
--- repo-orig/test_image.py	Fri Mar 08 20:37:32 2024
+++ repo/test_image.py	Fri Mar 08 21:36:31 2024
@@ -4,6 +4,7 @@
 
 import numpy as np
 import argparse
+import importlib
 import torch
 from src.transform import SSDTransformer
 import cv2
@@ -20,19 +21,38 @@
     parser.add_argument("--nms-threshold", type=float, default=0.5)
     parser.add_argument("--pretrained-model", type=str, default="trained_models/SSD.pth")
     parser.add_argument("--output", type=str, default=None, help="the path to output image")
+    parser.add_argument("--dataset", default='Cognata', type=str)
+    parser.add_argument("--config", default='config', type=str)
     args = parser.parse_args()
     return args
 
 
 def test(opt):
-    model = SSD(backbone=ResNet())
-    checkpoint = torch.load(opt.pretrained_model)
+    import os
+    device = os.environ.get('CM_DEVICE','')
+    if device == 'cuda' and not torch.cuda.is_available():
+        print ('')
+        print ('Error: CUDA is forced but not available...')
+        exit(1)
+
+    to_export_model = os.environ.get('CM_ABTF_EXPORT_MODEL_TO_ONNX','')
+    exported = False
+
+    config = importlib.import_module('config.' + opt.config)
+    image_size = config.model['image_size']
+
+#    model = SSD(backbone=ResNet())
+    model = SSD(config.model, backbone=ResNet(config.model), num_classes=16) #num_classes)
+#    checkpoint = torch.load(opt.pretrained_model)
+    checkpoint = torch.load(opt.pretrained_model, map_location=torch.device(device))
     model.load_state_dict(checkpoint["model_state_dict"])
-    if torch.cuda.is_available():
+    if device=='cuda':
         model.cuda()
     model.eval()
-    dboxes = generate_dboxes()
-    transformer = SSDTransformer(dboxes, (300, 300), val=True)
+#    dboxes = generate_dboxes()
+    dboxes = generate_dboxes(config.model, model="ssd")
+
+    transformer = SSDTransformer(dboxes, image_size, val=True)
     img = Image.open(opt.input).convert("RGB")
     img, _, _, _ = transformer(img, None, torch.zeros(1,4), torch.zeros(1))
     encoder = Encoder(dboxes)
@@ -40,8 +60,23 @@
     if torch.cuda.is_available():
         img = img.cuda()
     with torch.no_grad():
-        ploc, plabel = model(img.unsqueeze(dim=0))
+        inp = img.unsqueeze(dim=0)
+        ploc, plabel = model(inp)
         result = encoder.decode_batch(ploc, plabel, opt.nms_threshold, 20)[0]
+
+        if to_export_model!='' and not exported:
+            torch.onnx.export(model,
+                 inp,
+                 to_export_model,
+                 verbose=True,
+                 input_names=['input'],
+                 output_names=['output'],
+                 export_params=True,
+                 )
+
+            exported = True     
+        
+        
         loc, label, prob = [r.cpu().numpy() for r in result]
         best = np.argwhere(prob > opt.cls_threshold).squeeze(axis=1)
         loc = loc[best]
@@ -54,6 +89,7 @@
             loc[:, 1::2] *= height
             loc = loc.astype(np.int32)
             for box, lb, pr in zip(loc, label, prob):
+#                category = test_set.label_info[lb]
                 category = coco_classes[lb]
                 color = colors[lb]
                 xmin, ymin, xmax, ymax = box
