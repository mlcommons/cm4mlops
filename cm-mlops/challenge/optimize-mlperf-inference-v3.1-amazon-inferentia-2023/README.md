### Challenge

Develop a reference implementation of any MLPerf inference benchmark to run on Amazon Inferentia.

*The first implementation will receive 3 points and a prize of 400$ and the fastest implementation will receive a prize of 300$.
All submitters will participate in writing a common white paper about 
running and comparing MLPerf inference benchmarks out-of-the-box.*

Join this public [Discord server](https://discord.gg/JjWNWXKxwT) to get more details
and help from the organizers and the community.

Read [this documentation](https://github.com/mlcommons/ck/blob/master/docs/mlperf/inference/README.md) 
to run reference implementations of MLPerf inference benchmarks 
using the CM automation language and use them as a base for your developments.


### Organizers

* [MLCommons](https://cKnowledge.org/mlcommons-taskforce)
* [cTuning.org](https://www.linkedin.com/company/ctuning-foundation)
* [cKnowledge.org](https://www.linkedin.com/company/cknowledge)


### Results
