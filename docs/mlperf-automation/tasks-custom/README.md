**[ [TOC](../README.md) ]**

# Customize MLPerf&trade; inference benchmark

Here we describe how to customize MLPerf&trade; inference benchmark 
to automate design space exploration across different models, frameworks and data sets 
with the help of the [CK workflow framework](https://github.com/mlcommons/ck).


We collect all CK components for MLPerf and MLSystems co-design in one CK repository: https://github.com/mlcommons/ck-mlops .

We plan to test, unify and standardize them during summer 2021. 
In the meantime you can have a look at [these examples](../reproduce/README.md)
and the following CK components for ML Systems benchmarking:
* [Program workflows](https://github.com/mlcommons/ck-mlops/tree/main/program)
* [Packages with frameworks, models, data sets and quantization scripts](https://github.com/mlcommons/ck-mlops/tree/main/package)
* [SUT descriptions](https://github.com/mlcommons/ck-mlops/tree/main/sut)
* [Docker images](https://github.com/mlcommons/ck-mlops/tree/main/docker)
* [Aux scripts](https://github.com/mlcommons/ck-mlops/tree/main/script)


TBD:

* [Image classification](task-image-classification.md)
* [Object detection](task-object-detection.md)
* [Medical imaging ](task-medical-imaging.md)
* [NLP](task-nlp.md)
* [Recommendation](task-recommendation.md)
* [Speech recognition](task-speech-recognition.md)




# Feedback
* Contact: grigori@octoml.ai
