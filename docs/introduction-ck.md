[ [Back to index](README.md) ]

# Introduction to the MLCommons CK playground

[Collective Knowledge playground (MLCommons CK)](https://x.cKnowledge.org)
is an open-source and technology-agnostic on-prem SaaS platform
being developed by [MLCommons Task Force on Automation and Reproducibility](taskforce.md)
and [cKnowledge.org](https://cKnowledge.org).
 
CK is intended to help everyone from a company expert to a child
to automatically reproduce, optimize, integrate and deploy the state-of-the-art AI/ML solutions
in the real-world in the fastest and most efficient way while slashing all research, development, optimization and operational costs.

CK playground is powered by the portable, technology-agnostic, human-readable and open-source
[Collective Mind automation language](introduction-cm.md) adopted and extended by [MLCommons (50+ companies and universities)](https://mlcommons.org)
to collaboratively benchmark and optimize AI and ML systems across diverse software, hardware, models and data from different vendors.

While still in the prototyping stage, our open-source technology already helps MLCommons organizations, students and researchers 
automate and optimize [MLPerf benchmark submissions](https://access.cknowledge.org/playground/?action=experiments)
while contributing to more than half of all performance and power results for MLPerf inference benchmark since the beginning.

Read more about our long-term vision and the next plans in our 
[ACM REP'23 keynote "Toward a common language to facilitate reproducible research and technology transfer: challenges and solutions"]( https://doi.org/10.5281/zenodo.8105339 ).

See a few real-world examples of using the CK playground powered by the CM language:

- [Organizing reproducibility, replicability and optimization challenges](https://access.cknowledge.org/playground/?action=challenges&name=57cbc3384d7640f9)
- [Reproducing MLPerf inference benchmark and automating submissions](https://cKnowledge.org/mlperf-inference-gui)
- [Visualizing and comparing MLPerf inference benchmark results](https://access.cKnowledge.org/playground/?action=experiments&tags=mlperf-inference,all,open,edge,image-classification,singlestream)
- [Sharing reproducibility reports]( https://cKnowledge.org/mlperf-inf-v3.0-reproducibility-report )
- [Adding derived metrics such as power efficiency and/or cost efficiency]( https://cKnowledge.org/mlcommons-inference-gui )

Feel free to participate in the [reproducibility and optimization challenges](https://access.cknowledge.org/playground/?action=challenges)!

